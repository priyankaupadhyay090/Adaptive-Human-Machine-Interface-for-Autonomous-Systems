{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgnndtomSJu6",
        "outputId": "f63cb9aa-2cb0-433b-a04d-b3194bf75150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-0.24.1-py3-none-any.whl (7.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4 MB 11.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.24.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n",
            "Collecting pickle-mixin\n",
            "  Downloading pickle-mixin-1.0.2.tar.gz (5.1 kB)\n",
            "Building wheels for collected packages: pickle-mixin\n",
            "  Building wheel for pickle-mixin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle-mixin: filename=pickle_mixin-1.0.2-py3-none-any.whl size=6008 sha256=255cbb87617612c0eb77c88d29da8dd86934a0b0a5e99887f70fd9269e266703\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/70/0b/673e09a7ed429660d22352a1b117b4f616a8fc054bdd7eb157\n",
            "Successfully built pickle-mixin\n",
            "Installing collected packages: pickle-mixin\n",
            "Successfully installed pickle-mixin-1.0.2\n"
          ]
        }
      ],
      "source": [
        "# Install required packages \n",
        "!pip install mne\n",
        "!pip install torch\n",
        "!pip install matplotlib\n",
        "!pip install scikit-learn\n",
        "!pip install pandas\n",
        "!pip install scikit-optimize\n",
        "!pip install pickle-mixin\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KpF2IaTeTWFu"
      },
      "outputs": [],
      "source": [
        "# import general modules\n",
        "import os\n",
        "import copy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import torch\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import mne\n",
        "from mne.externals.pymatreader import read_mat\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "import itertools\n",
        "from glob import glob\n",
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn import svm \n",
        "from sklearn.svm import SVC \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from skopt import BayesSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1vkW_V0TAaRT"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2abZMJ0TZKR",
        "outputId": "94c238c2-a3c0-43ff-bb6e-c8777bb74851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Set the data_path \n",
        "data_path = os.getcwd()\n",
        "print(data_path)\n",
        "cognitive_load_level = ['MATBeasy', 'MATBmed', 'MATBdiff']\n",
        "# ['MATBeasy', 'MATBmed', 'MATBdiff']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CyF2Jpp8UQd8"
      },
      "outputs": [],
      "source": [
        "# Read Electrodes channels names and position\n",
        "channels_info = pd.read_csv(data_path + '/drive/MyDrive/Colab Notebooks/Dataset/Electrodes/chan_locs_standard', names=['ch_names','x','y','z'],sep ='\\t') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "17CIo5V21BQG"
      },
      "outputs": [],
      "source": [
        "\n",
        "# data_path = os.getcwd()\n",
        "# no_of_subjects = 15\n",
        "# no_of_sessions = 2 #  only 2 sessions out of 3 includes all Three cognitive load level task \n",
        "\n",
        "# data = []\n",
        "# labels = [] # class labels: 0,1,2\n",
        "\n",
        "# #Electrodes\n",
        "# # ch_slice = ['AF3','AFz','AF4','AF8','F1','Fz','F2','F4','F6','F8','FC3','T7','C5','C3','C4','TP7','CP5','CP3','CP1','CPz','P7','P5','P3','P8','POz','PO4','PO6','PO8','O1','OZ','O2','Iz']\n",
        "\n",
        "# for subject_n, session_n in itertools.product(range(no_of_subjects), range(no_of_sessions)): # iterate through all the dataset folders and sessions\n",
        "#   '''\n",
        "#   data : np.ndarray\n",
        "#         The epochs data, shape (n_epochs, n_channels, n_times).\n",
        "#   label : np.ndarray\n",
        "#         The epochs labels, shape (n_epochs,)\n",
        "#   no_of_subjects : Subject number\n",
        "#   no_of_sessions : Session number\n",
        "\n",
        "#   '''\n",
        "#   print(subject_n)\n",
        "#   for label_id, mental_load_level in enumerate(cognitive_load_level): # for label ID and class level in dataset \n",
        "#         # get the subject number\n",
        "#         subject = 'P{0:02d}'.format(subject_n+1) # goes till P01 to P07 \n",
        "#         # fetch the session\n",
        "#         session = f'S{session_n+1}'\n",
        "#         path = os.path.join(os.path.join(data_path + '/drive/MyDrive/Colab Notebooks/Dataset', subject), session) + f'/eeg/alldata_sbj{str(subject_n+1).zfill(2)}_sess{session_n+1}_{mental_load_level}.set' # left zero padding with zfill(2)\n",
        "#         read_epochs_per_participant = mne.io.read_epochs_eeglab(path, verbose=False)\n",
        "\n",
        "#         #Drop the channels\n",
        "#         # read_epochs_per_participant = read_epochs_per_participant.drop_channels(list(set(read_epochs_per_participant.ch_names)-set(ch_slice)))\n",
        "\n",
        "#         # collect the train data for all three mental load\n",
        "#         data_per_mental_load = read_epochs_per_participant.get_data()\n",
        "#         data.extend(data_per_mental_load))\n",
        "#         labels.extend([label_id]*len(data_per_mental_load))\n",
        "#         data_tmp = np.array(data)\n",
        "#         labels_tmp = np.array(labels)\n",
        "#         data_tmp = data_tmp.reshape(data_tmp.shape[0],-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9HihFH_8Cwzp"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Code/data_tmp.pkl', 'rb') as file:\n",
        "  data_tmp = pickle.load(file)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Code/labels_tmp.pkl', 'rb') as file:\n",
        "  labels_tmp = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KoTJxUXqWklz"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_tmp, labels_tmp, test_size=0.3,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "w3oZh2W4TMdn"
      },
      "outputs": [],
      "source": [
        " scaler = StandardScaler()\n",
        "         \n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eeCx2FkmFF9F"
      },
      "outputs": [],
      "source": [
        "# Function to compute the classification using SVM\n",
        "def compute_SVC(train_f,train_l):\n",
        "    c = SVC(decision_function_shape = 'ovo', kernel='rbf')\n",
        "    c.fit(train_f,train_l)\n",
        "    return c;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g1x3NwjLFoMT"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(test_f,test_l,c):\n",
        "    pred = c.predict(test_f)\n",
        "    pred_accu = accuracy_score(test_l,pred)\n",
        "    return pred_accu;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h9tcwlHRFUgD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "e07467e3-bd90-460a-d92c-6f79045cf9fe"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-62b3ded42428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_svc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_SVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maccu_percent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_svc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy obtained over the whole training set is:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'compute_SVC' is not defined"
          ]
        }
      ],
      "source": [
        "model_svc = compute_SVC(X_train, y_train);\n",
        "accu_percent = compute_accuracy(X_test,y_test,model_svc)*100;\n",
        "\n",
        "print('Accuracy obtained over the whole training set is:')\n",
        "print(accu_percent)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iAbwyXxGH7K"
      },
      "outputs": [],
      "source": [
        "  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SVM+BayesSearch",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}